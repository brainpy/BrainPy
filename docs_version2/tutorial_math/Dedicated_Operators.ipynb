{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e49b8f",
   "metadata": {},
   "source": [
    "# Dedicated Operators\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brainpy/brainpy/blob/master/docs/tutorial_math/Dedicated_Operators.ipynb)\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/brainpy/brainpy/blob/master/docs/tutorial_math/Dedicated_Operators.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bcbd04",
   "metadata": {},
   "source": [
    "@[Xiaoyu Chen](mailto:c-xy17@tsinghua.org.cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7f110",
   "metadata": {},
   "source": [
    "In the previous section, we have learned that BrainPy offers `brainpy.math.array` that support common NumPy-like operations, which brings great convenience to users familiar with NumPy. NumPy-like operations, however, does not always apply to brain dynamics modeling. As one may recognize, the most costive computation in brain dynamics modeling lies in synaptic computation, as it involves the connection between two neuron groups. Two of the most salient features of synaptic computation are:\n",
    "1. **Sparse connection**: neuron-neuron connection in most brain regions is sparse.\n",
    "2. **Event-driven synaptic transmission**: synaptic transmission happens only when the presynaptic neurons fire.\n",
    "\n",
    "If we stick to array-related operations, there rise some problems making the computation extremely inefficient:\n",
    "1. Because of sparse connection, keeping using traditional array operations (e.g., matrix multiplication) will cause a huge waste in memory allocation and computation.\n",
    "2. Because of event-driven synaptic transmission, only a small proportion of presynaptic neurons are activated at a time, resulting in sparse transmission from pre- to post-synaptic neuron populations. Traditional array operations will compute the transmission based on the connection from all presynaptic neurons to their postsynaptic elements, unable to exclude those inactive neurons and to avoid redundant computation. \n",
    "\n",
    "To show these two features more intuitively, here is an illustration of computing postsynaptic inputs from presynaptic events and their connection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0831d0",
   "metadata": {},
   "source": [
    "<img src=\"../_static/sparse_connection_and_events.png\" width=\"360 px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd0f86",
   "metadata": {},
   "source": [
    "In essence, **the synaptic computation is the multiplication of a vector and a matrix**. If presynaptic events and synaptic connection are both sparse, it will be extremely wasteful to use NumPy-like matrix multiplication.\n",
    "\n",
    "In this section, we are introducing some decicated operators for sparse and event-driven computation to make brain dynamics modeling much more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c25d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "\n",
    "bm.set_platform('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018af2b3",
   "metadata": {},
   "source": [
    "## Operators for sparse synaptic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1307f",
   "metadata": {},
   "source": [
    "Firstly, let's consider the situation when **the synaptic connection is sparse**. Here is an example of the connection between two groups of neurons:\n",
    "\n",
    "<img src=\"../_static/example_synaptic_connection.png\" width=\"300 px\" align=\"center\">\n",
    "\n",
    "The yellow numbers on the connection lines indicate the connection weights. We can convert the connection pattern into a connection matrix, where each row represents a presynaptic neuron and each column represents a postsynaptic neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de2e835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([[0., 0., 1., 2., 3.],\n",
       "                   [4., 0., 5., 0., 6.],\n",
       "                   [0., 7., 0., 0., 0.]]),\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_mat = bm.array([[0, 0, 1, 2, 3], \n",
    "                     [4, 0, 5, 0, 6], \n",
    "                     [0, 7, 0, 0, 0]]).astype(float)\n",
    "conn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47598d",
   "metadata": {},
   "source": [
    "Assume that at a given time, presynaptic neurons are active with different values (2, 1, 3), so the postsynaptic inputs from these three presynaptic neurons can be computed as **the multiplication of a vector and a sparse matrix**:\n",
    "\n",
    "<img src=\"../_static/sparse_matrix_multiplication.png\" width=\"450 px\" align=\"center\">\n",
    "\n",
    "In which the presynaptic activity is displayed as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23a29d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(value=Array([ 4., 21.,  7.,  4., 12.]), dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_activity = bm.array([2., 1., 3.])\n",
    "\n",
    "bm.matmul(pre_activity, conn_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99805a6e",
   "metadata": {},
   "source": [
    "While this multiplication is intuitive, the computation is inefficient if the connection matrix is sparse. To save memory storage and improve running efficiency, we can use other data structures to store the sparse connection without so many empty values. One of the data structures is the **Compressed Sparse Row (CSR) matrix**.\n",
    "\n",
    "Simply speaking, the CSR matrix stores the connection information by three vectors: the non-zero weight values in the connection matrix, the post-synaptic neuron indices, and the corresponding presynaptic neuron pointers (users can see the `pre2post` connection properties in [Synaptic Connections](../tutorial_toolbox/synaptic_connetions.ipynb) for more information). Without knowing the details, the vectors can still easily be obtained by the following operations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed675e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([1., 2., 3., 4., 5., 6., 7.], dtype=float32),\n",
       " Array([2, 3, 4, 0, 2, 4, 1], dtype=int32),\n",
       " Array([0, 3, 6, 7], dtype=int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = conn_mat[bm.nonzero(conn_mat)]\n",
    "\n",
    "# difine a connection from a connection matrix by brainpy.conn.Matconn \n",
    "connection = bp.conn.MatConn(conn_mat.value)\n",
    "# obtain these properties by .require('pre2post')\n",
    "indices, indptr = connection(conn_mat.shape[0], conn_mat.shape[1]).require('pre2post')\n",
    "\n",
    "data, indices, indptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92801d",
   "metadata": {},
   "source": [
    "Then we can use the dedicated operators `brainpy.math.sparse.csrmv` to compute the postsynaptic inputs (i.e., the product of a **CSR** **M**atrix and a **V**ector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce6fd5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 4., 21.,  7.,  4., 12.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.sparse.csrmv(data, indices=indices, indptr=indptr, vector=pre_activity, \n",
    "                shape=conn_mat.shape, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb1e7a",
   "metadata": {},
   "source": [
    "In which the non-zero connection values, the postsynaptic indices, the presynaptic neuron pointers, the presynaptic activity, and the connection shape (a tuple of the number of pre- and post-synaptic neurons) and whether to transpose the sparse matrix are passed to the fucntion. It returns the same results, but with a higher speed if the connection is sparse (we will see the comparison of their running time shortly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a0b55",
   "metadata": {},
   "source": [
    "## Operators for event-driven synaptic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a136da",
   "metadata": {},
   "source": [
    "Above we have talked about the situation when the synaptic connection is sparse. What if the presynaptic events are also sparse? Theoretically, more time will be saved if we remove the redundant computation of the connection from inactive presynaptic neurons. In this condition, we can use event-driven operators in `brainpy.math.event`.\n",
    "\n",
    "Assume that in the above example, the presynaptic neuron 0 and 1 are firing and neuron 2 is inactive (now their acitivities are represented by boolean values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5ae76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = bm.array([True, True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc37c1a4",
   "metadata": {},
   "source": [
    "The multiplication of the event vector and the connection matrix now becomes:\n",
    "\n",
    "<img src=\"../_static/event_driven_matrix_multiplication.png\" width=\"450 px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f583570",
   "metadata": {},
   "source": [
    "Of course we can use traditional matrix multiplication operators and the `brainpy.math.sparse.csrmv` operator for computation. However, by simply changing `brainpy.math.sparse.csrmv` to `brainpy.math.event.csrmv`, we can achieve event-driven synaptic computation and become even faster: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08121b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([4., 0., 6., 2., 9.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.event.csrmv(data, indices=indices, indptr=indptr, events=event, \n",
    "               shape=conn_mat.shape, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957caeb1",
   "metadata": {},
   "source": [
    "Note that the parameter `vector` in `brainpy.math.sparse.csrmv` is revised to a boolean-type array `events` in `brainpy.math.event.csrmv`.\n",
    "\n",
    "Now let's compare the efficiency of traditional matrix operators, `brainpy.math.sparse.csrmv`, and `brainpy.math.event.csrmv`. To show a significant difference, a much larger network is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c434d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "pre_num, post_num = 15000, 10000  # network size\n",
    "\n",
    "event = bm.random.bernoulli(p=0.15, size=pre_num)  # 15% of presynaptic neurons are active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b11a41",
   "metadata": {},
   "source": [
    "The traditional matrix operator is tested first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "072d19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for weight matrix generation: 4.558527099999992 s\n"
     ]
    }
   ],
   "source": [
    "# generate the weight matrix\n",
    "start = default_timer()\n",
    "\n",
    "connection_weights = bm.random.uniform(size=(pre_num, post_num))\n",
    "connection_weights[connection_weights < 0.8] = 0.  # sparse connection: 20%\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent for weight matrix generation: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2ce5337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for synaptic computation: 0.03688780000001657 s\n"
     ]
    }
   ],
   "source": [
    "# traditional matrix operator\n",
    "start = default_timer()\n",
    "\n",
    "post = bm.matmul(event, connection_weights)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent for synaptic computation: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724bfc23",
   "metadata": {},
   "source": [
    "**Note that to exclude the time for JIT compilation, the code was run twice and the second result is displayed**. Though the running time for `brainpy.math.matmul` is acceptable, a huge amount of time is spent on weight matrix generation, which is extremely inefficient.\n",
    "\n",
    "For sparse matrix, using the CSR matrix structure to store data and to compute the product is more efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfecf646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for connection generation: 1.61494689999995 s\n"
     ]
    }
   ],
   "source": [
    "# generate connection and store it in a CSR matrix\n",
    "start = default_timer()\n",
    "\n",
    "# define a connection with fixed connection probability by brainpy.conn.FixedProb\n",
    "connection = bp.conn.FixedProb(prob=0.2)\n",
    "# obtain these properties by .require('pre2post')\n",
    "indices, indptr = connection(pre_num, post_num).require('pre2post')\n",
    "data = bm.random.uniform(size=indices.shape)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent for connection generation: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d11f8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for synaptic computation: 0.0551689000000124 s\n"
     ]
    }
   ],
   "source": [
    "# dedicated sparse operator\n",
    "pre_activity = event.astype(float)\n",
    "\n",
    "start = default_timer()\n",
    "\n",
    "post = bm.sparse.csrmv(data, indices=indices, indptr=indptr, vector=pre_activity, \n",
    "                       shape=(pre_num, post_num), transpose=True)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent for synaptic computation: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457fa96c",
   "metadata": {},
   "source": [
    "Due to a large number of inactive presynaptic neurons, sparse connection matrix is not the optimal solution until event-driven computation is involved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "213c43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for synaptic computation: 0.015149300000018684 s\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "\n",
    "post = bm.event.csrmv(data, indices=indices, indptr=indptr, events=event, \n",
    "                      shape=(pre_num, post_num), transpose=True)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent for synaptic computation: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59f95e",
   "metadata": {},
   "source": [
    "Now the running time is significantly lower than the other two operators.\n",
    "\n",
    "To summarize, for synaptic computation with a sparse connection matrix, operators in `brainpy.math.sparse` are recommended. Furthermore, if the presynaptic activity is also sparse, operators in `brainpy.math.event` are better choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240aee1f",
   "metadata": {},
   "source": [
    "## Even faster synaptic computation with specific connection patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae4bc1",
   "metadata": {},
   "source": [
    "The synaptic computation, the multiplication of a vector and a sparse matrix, though impressively accelerated by the event-driven and sparse operators in BrainPy, can be improved even further in some situations. \n",
    "\n",
    "When building a brain model, we often encounter situations like this: \n",
    "1. each presynaptic neuron is randomly connected with postsynaptic neurons in a fixed probability, and \n",
    "2. the connection weights obey certain rules, such as being a constant value or generated from a normal distribution. \n",
    "\n",
    "One solution is to generate the random connection and the corresponding weights and store them in a sparse matrix, and then use BrainPy's dedicated operators for synaptic computation. To further improve the performance, BrainPy provides another solution, which is to generate the connection information during synaptic computation, thusing saving the space to store connection and the time to interact with memory.\n",
    "\n",
    "Currently, BrainPy provides two types of such operators, one of which is regular and the other is event-driven. They are contained in `brainpy.math.jitconn`, which means the random connection is just-in-time generated during computation. Let's take as an example the event-driven operator to compute synaptic transmission when 1. the connection matrix is randomly generated with a fixed probability and 2. the conection weights are generated from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b504e8",
   "metadata": {},
   "source": [
    "Firstly, let's think of how this is achieved without any dedicated operators. Below are the related parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6461bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_num, post_num = 50000, 10000  # network size\n",
    "conn_prob = 0.1  # connection probability\n",
    "w_mu, w_sigma = 0.5, 1.  # parameters of the normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019b22d",
   "metadata": {},
   "source": [
    "And a vector representing presynaptic acitivty is also needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92ecfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = bm.random.bernoulli(p=0.2, size=pre_num)  # 20% of presynaptic neurons release spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88136f1",
   "metadata": {},
   "source": [
    "To obtain a random connection with fixed probability, we need to generate a bool-type connection matrix. To obtain a normally distributed weight matrix, we should also generate a weight matrix with float numbers. Then we can compute the postsynaptic inputs by multiplying the event vector and the elementwise product of the connection and the weight matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a017ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: 11.050910799999997 s\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "\n",
    "# generate the connection matrix using brainpy.connect.FixedProb\n",
    "conn = bp.connect.FixedProb(prob=conn_prob)(pre_num, post_num)\n",
    "conn_matrix = conn.require('conn_mat')\n",
    "\n",
    "# generate the weight matrix\n",
    "weight_matrix = bm.random.normal(loc=w_mu, scale=w_sigma, size=(pre_num, post_num))\n",
    "\n",
    "# compute the product\n",
    "post = bm.matmul(event, weight_matrix * conn_matrix)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89a99c",
   "metadata": {},
   "source": [
    "The total running time is about 10 seconds. Now let's try to use `brainpy.math.event.csrmv` to see how much improvement it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bf35974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: 4.693945999999983 s\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "\n",
    "# generate the connection with the pre2post structure\n",
    "conn = bp.connect.FixedProb(prob=conn_prob)(pre_num, post_num)\n",
    "indices, indptr = conn.require('pre2post')\n",
    "\n",
    "# generate the weight matrix\n",
    "weights = bm.random.normal(loc=w_mu, scale=w_sigma, size=indices.shape[0])\n",
    "\n",
    "# compute the event-driven synaptic summation\n",
    "post = bm.event.csrmv(weights, indices, indptr, event, shape=(pre_num, post_num), \n",
    "                      transpose=True)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d899e91",
   "metadata": {},
   "source": [
    "Now the running time halves, but it is still unsatisfactory. Then we try to use a new operator, `brainpy.math.jitconn.event_mv_prob_normal`, which does not generate the connection and weights explicitly but achieves it while doing the matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cac037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: 0.0062690999999404085 s\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "\n",
    "# the connection is generated during computation, \n",
    "# so the entire connection information is not required to be stored or accessed\n",
    "post = bm.jitconn.event_mv_prob_normal(event, w_mu=w_mu, w_sigma=w_sigma, conn_prob=conn_prob, \n",
    "                                       shape=(pre_num, post_num), transpose=True)\n",
    "\n",
    "duration = default_timer() - start\n",
    "\n",
    "print('time spent: {} s'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47561648",
   "metadata": {},
   "source": [
    "Surprisingly, the time spent is much less than the privous operations! Therefore, users are recommended to use these operators to multiply a vector and a sparse matrix if the situation is as follows:\n",
    "\n",
    "1. Use `brainpy.math.jitconn.mv_prob_homo()`, if the connection is of fixed probability, and the connection weight is a constant (a single value).\n",
    "2. Use `brainpy.math.jitconn.mv_prob_uniform()`, if the connection is of fixed probability, and the connection weight is sampled from a uniform distribution.\n",
    "3. Use `brainpy.math.jitconn.mv_prob_normal()`, if the connection is of fixed probability, and the connection weight is sampled from a normal distribution.\n",
    "\n",
    "Besides, there are three corresponding event-driven operators, `brainpy.math.jitconn.event_mv_prob_homo()`, `brainpy.math.jitconn.event_mv_prob_uniform()`, and `brainpy.math.jitconn.event_mv_prob_normal()`, for event-driven synaptic computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8db84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
