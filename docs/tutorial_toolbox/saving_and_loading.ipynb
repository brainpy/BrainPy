{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5662bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Saving and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea6a94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "@[Chaoming Wang](https://github.com/chaoming0625)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba75189",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Being able to save and load the variables of a model is essential in brain dynamics programming. In this tutorial we describe how to save/load the variables in a  model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff1932c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "\n",
    "bp.math.set_platform('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef65b38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving and loading variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8512796",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Model saving and loading in BrainPy are implemented with ``.save_states()`` and ``.load_states()`` functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32688caf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "BrainPy supports saving and loading model variables with various Python standard file formats, including\n",
    "\n",
    "- HDF5: ``.h5``, ``.hdf5``\n",
    "\n",
    "- ``.npz`` (NumPy file format)\n",
    "\n",
    "- ``.pkl`` (Python’s pickle utility)\n",
    "\n",
    "- ``.mat`` (Matlab file format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7ac95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here’s a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc2cab20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EINet(bp.dyn.Network):\n",
    "    def __init__(self, num_exc=3200, num_inh=800, method='exp_auto'):\n",
    "        # neurons\n",
    "        pars = dict(V_rest=-60., V_th=-50., V_reset=-60., tau=20., tau_ref=5.)\n",
    "        E = bp.models.LIF(num_exc, **pars, method=method)\n",
    "        I = bp.models.LIF(num_inh, **pars, method=method)\n",
    "        E.V[:] = bp.math.random.randn(num_exc) * 2 - 55.\n",
    "        I.V[:] = bp.math.random.randn(num_inh) * 2 - 55.\n",
    "\n",
    "        # synapses\n",
    "        E2E = bp.models.ExpCOBA(E, E, bp.conn.FixedProb(prob=0.02),\n",
    "                                E=0., g_max=0.6, tau=5., method=method)\n",
    "        E2I = bp.models.ExpCOBA(E, I, bp.conn.FixedProb(prob=0.02),\n",
    "                                E=0., g_max=0.6, tau=5., method=method)\n",
    "        I2E = bp.models.ExpCOBA(I, E, bp.conn.FixedProb(prob=0.02),\n",
    "                                E=-80., g_max=6.7, tau=10., method=method)\n",
    "        I2I = bp.models.ExpCOBA(I, I, bp.conn.FixedProb(prob=0.02),\n",
    "                                E=-80., g_max=6.7, tau=10., method=method)\n",
    "\n",
    "        super(EINet, self).__init__(E2E, E2I, I2E, I2I, E=E, I=I)\n",
    "        \n",
    "        \n",
    "net = EINet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edbfcc58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./data'): \n",
    "    os.makedirs('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621ac319",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model saving\n",
    "\n",
    "net.save_states('./data/net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9132f1c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model loading\n",
    "\n",
    "net.load_states('./data/net.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeba1f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- ``.save_states(filename, all_var=None)`` function receives a string to specify the output file name. If ``all_vars`` is not provided, BrainPy will retieve all variables in the model though the relative path. \n",
    "- ``.load_states(filename, verbose, check_missing)`` function receives several arguments. The first is a string of the output file name. The second \"verbose\" specifies whether report the loading progress. The final argument \"check_missing\" will warn the variables of the model which missed  in the output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79192ea1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:brainpy.base.io:There are variable states missed in ./data/net.h5. The missed variables are: ['ExpCOBA0.pre.V', 'ExpCOBA0.pre.input', 'ExpCOBA0.pre.refractory', 'ExpCOBA0.pre.spike', 'ExpCOBA0.pre.t_last_spike', 'ExpCOBA1.pre.V', 'ExpCOBA1.pre.input', 'ExpCOBA1.pre.refractory', 'ExpCOBA1.pre.spike', 'ExpCOBA1.pre.t_last_spike', 'ExpCOBA1.post.V', 'ExpCOBA1.post.input', 'ExpCOBA1.post.refractory', 'ExpCOBA1.post.spike', 'ExpCOBA1.post.t_last_spike', 'ExpCOBA2.pre.V', 'ExpCOBA2.pre.input', 'ExpCOBA2.pre.refractory', 'ExpCOBA2.pre.spike', 'ExpCOBA2.pre.t_last_spike', 'ExpCOBA2.post.V', 'ExpCOBA2.post.input', 'ExpCOBA2.post.refractory', 'ExpCOBA2.post.spike', 'ExpCOBA2.post.t_last_spike', 'ExpCOBA3.pre.V', 'ExpCOBA3.pre.input', 'ExpCOBA3.pre.refractory', 'ExpCOBA3.pre.spike', 'ExpCOBA3.pre.t_last_spike'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading E.V ...\n",
      "Loading E.input ...\n",
      "Loading E.refractory ...\n",
      "Loading E.spike ...\n",
      "Loading E.t_last_spike ...\n",
      "Loading ExpCOBA0.g ...\n",
      "Loading ExpCOBA0.pre_spike.data ...\n",
      "Loading ExpCOBA0.pre_spike.in_idx ...\n",
      "Loading ExpCOBA0.pre_spike.out_idx ...\n",
      "Loading ExpCOBA1.g ...\n",
      "Loading ExpCOBA1.pre_spike.data ...\n",
      "Loading ExpCOBA1.pre_spike.in_idx ...\n",
      "Loading ExpCOBA1.pre_spike.out_idx ...\n",
      "Loading ExpCOBA2.g ...\n",
      "Loading ExpCOBA2.pre_spike.data ...\n",
      "Loading ExpCOBA2.pre_spike.in_idx ...\n",
      "Loading ExpCOBA2.pre_spike.out_idx ...\n",
      "Loading ExpCOBA3.g ...\n",
      "Loading ExpCOBA3.pre_spike.data ...\n",
      "Loading ExpCOBA3.pre_spike.in_idx ...\n",
      "Loading ExpCOBA3.pre_spike.out_idx ...\n",
      "Loading I.V ...\n",
      "Loading I.input ...\n",
      "Loading I.refractory ...\n",
      "Loading I.spike ...\n",
      "Loading I.t_last_spike ...\n"
     ]
    }
   ],
   "source": [
    "# model loading with warning and checking\n",
    "\n",
    "net.load_states('./data/net.h5', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34074f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```{note}\n",
    "By default, the model variables are retrived by the relative path. Relative path retrival usually results in duplicate variables in the returned TensorCollector. Therefore, there will always be missing keys when loading the variables. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422be59e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Custom saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef7f2d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can make your own saving and loading functions easily. Beacause all variables in the model can be easily collected through ``.vars()``. Therefore, saving variables is just transforming these variables to numpy.ndarray and then storing them into the disk. Similarly, to load variables, you just need read the numpy arrays from the disk and then transform these arrays as instances of [Variables](../tutorial_math/variables.ipynb). \n",
    "\n",
    "The only gotcha to pay attention to is to avoid saving duplicated variables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainpy",
   "language": "python",
   "name": "brainpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}